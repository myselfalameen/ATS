{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEuD9tDeI_yM",
        "outputId": "44959aba-5d81-46f2-b8f0-14aeb04e7bad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from openpyxl import Workbook, load_workbook\n",
        "import os\n",
        "\n",
        "# Load Sentence Transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Editable job description\n",
        "job_description = \"\"\"\n",
        "•\tEvaluate new product requests and provide technical recommendations\n",
        "•\tAct as an expert in the development of purchased or manufactured products\n",
        "•\tPerform tests, develop protocols, and analyze results\n",
        "•\tCommunicate directly with franchisees and the customer service team to address technical inquiries\n",
        "•\tConduct on-site studies and 3D scans in various locations (residences, hotels, cruise ships)\n",
        "•\tPresent new products to internal teams and the franchise network through interactive demonstrations\n",
        "•\tContribute to the product certification process and ensure compliance with manufacturing standards\n",
        "\"\"\"\n",
        "\n",
        "# Extract text from a Word document\n",
        "def extract_text_from_cv(cv_path):\n",
        "    doc = docx.Document(cv_path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "# Extract skills from job description\n",
        "def extract_skills_from_job_description(job_desc):\n",
        "    words = re.findall(r'\\b[A-Za-z]+\\b', job_desc)\n",
        "    return list(set([w.lower() for w in words if len(w) > 2 and w.lower() not in [\"the\", \"and\", \"for\", \"with\", \"you\", \"are\", \"our\", \"etc\"]]))\n",
        "\n",
        "# Extract skills from CV based on job description\n",
        "def extract_skills_from_cv(cv_text, job_skills):\n",
        "    return [skill for skill in job_skills if skill in cv_text.lower()]\n",
        "\n",
        "# Extract experience sentences\n",
        "def extract_experience_from_cv(cv_text):\n",
        "    keywords = [\"experience\", \"worked\", \"internship\", \"job\", \"project\"]\n",
        "    return [s.strip() for s in cv_text.split(\".\") if any(k in s.lower() for k in keywords)]\n",
        "\n",
        "# Extract education sentences\n",
        "def extract_education_from_cv(cv_text):\n",
        "    keywords = [\"degree\", \"university\", \"college\", \"bachelor\", \"master\", \"school\", \"education\"]\n",
        "    return [s.strip() for s in cv_text.split(\".\") if any(k in s.lower() for k in keywords)]\n",
        "\n",
        "# Calculate semantic similarity match score\n",
        "def semantic_match_score(cv_text, job_desc):\n",
        "    cv_embedding = model.encode(cv_text, convert_to_tensor=True)\n",
        "    job_embedding = model.encode(job_desc, convert_to_tensor=True)\n",
        "    score = util.pytorch_cos_sim(cv_embedding, job_embedding).item()\n",
        "    return round(score * 10, 2)\n",
        "\n",
        "# Analyze and return the CV info\n",
        "def analyze_cv(cv_path):\n",
        "    cv_text = extract_text_from_cv(cv_path)\n",
        "    job_skills = extract_skills_from_job_description(job_description)\n",
        "\n",
        "    skills = extract_skills_from_cv(cv_text, job_skills)\n",
        "    experience = extract_experience_from_cv(cv_text)\n",
        "    education = extract_education_from_cv(cv_text)\n",
        "    match_score = semantic_match_score(cv_text, job_description)\n",
        "\n",
        "    return {\n",
        "        \"File Name\": os.path.basename(cv_path),\n",
        "        \"Skills\": \", \".join(skills),\n",
        "        \"Experience\": \" | \".join(experience),\n",
        "        \"Education\": \" | \".join(education),\n",
        "        \"Match Score\": match_score\n",
        "    }\n",
        "\n",
        "# Save result to Excel (append if file exists)\n",
        "def save_to_excel(result, output_excel):\n",
        "    if not os.path.exists(output_excel):\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"ATS Results\"\n",
        "        ws.append([\"File Name\", \"Skills\", \"Experience\", \"Education\", \"Match Score\"])\n",
        "    else:\n",
        "        wb = load_workbook(output_excel)\n",
        "        ws = wb.active\n",
        "\n",
        "    ws.append([\n",
        "        result[\"File Name\"],\n",
        "        result[\"Skills\"],\n",
        "        result[\"Experience\"],\n",
        "        result[\"Education\"],\n",
        "        result[\"Match Score\"]\n",
        "    ])\n",
        "\n",
        "    wb.save(output_excel)\n",
        "\n",
        "# Main program\n",
        "def main():\n",
        "    output_excel = \"cv_results.xlsx\"\n",
        "    num_files = int(input(\"How many CVs would you like to analyze? \"))\n",
        "\n",
        "    for i in range(1, num_files + 1):\n",
        "        print(f\"\\n[{i}] Please enter the full path to CV #{i} (Word .docx file):\")\n",
        "        cv_path = input(\"> \").strip()\n",
        "\n",
        "        if not os.path.exists(cv_path) or not cv_path.endswith(\".docx\"):\n",
        "            print(\"❌ Invalid file. Please try again.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"✅ Analyzing {os.path.basename(cv_path)}...\")\n",
        "        result = analyze_cv(cv_path)\n",
        "        save_to_excel(result, output_excel)\n",
        "        print(f\"📄 Result for {result['File Name']} saved.\\n\")\n",
        "\n",
        "    print(f\"✅ All done! Results saved in '{output_excel}'\")\n",
        "\n",
        "# Run the script\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzx3pr76RBxD",
        "outputId": "6be84940-58bd-44aa-d6a1-64a1fb6611b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many CVs would you like to analyze? 2\n",
            "\n",
            "[1] Please enter the full path to CV #1 (Word .docx file):\n",
            "> /content/Initial CV Calgary (AutoRecovered).docx\n",
            "✅ Analyzing Initial CV Calgary (AutoRecovered).docx...\n",
            "📄 Result for Initial CV Calgary (AutoRecovered).docx saved.\n",
            "\n",
            "\n",
            "[2] Please enter the full path to CV #2 (Word .docx file):\n",
            "> /content/Initial CV.docx\n",
            "✅ Analyzing Initial CV.docx...\n",
            "📄 Result for Initial CV.docx saved.\n",
            "\n",
            "✅ All done! Results saved in 'cv_results.xlsx'\n"
          ]
        }
      ]
    }
  ]
}